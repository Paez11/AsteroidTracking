\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{datetime}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[right=2cm,left=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage[export]{adjustbox}
\usepackage{graphicx}
\usepackage{float}
\usepackage{changepage}
\usepackage{multicol}
\usepackage{imakeidx}
\usepackage{csquotes}
\usepackage{array}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage[backend=biber]{biblatex}
\addbibresource{webgrafia.bib}

\pagestyle{fancy}
\renewcommand{\footrulewidth}{0.4pt}
\setlength{\headheight}{15pt}


\fancyhead[L]{ CEIABD – BDA }
\fancyhead[R]{Páez Anguita, Víctor }
\fancyfoot[L]{IES Gran Capitán}

\begin{document}

\begin{titlepage}
    \begin{center}
      \Large \bfseries{}
    \end{center}
    \vspace{0.1cm}
    \begin{center}
      \Large \bfseries{}
    \end{center}
    \vspace{0.1cm}
    \begin{center}
     \Large \bfseries{AsteroidTracking}
    \end{center}
    \vspace{0.0001cm}
    \begin{center}
        Departamento de informática \\ I.E.S. Gran Capitán - Córdoba
    \end{center}
        \vspace{2 cm}
\begin{figure}[h!]
    \centering
    \includegraphics[width=.5\textwidth]{assets/portada.png}
    \label{fig:my_label}
\end{figure}
    \vspace{0.2 cm}
    \begin{center}
        Inteligencia artificial y Big data \\ \today 
    \end{center}
    \vspace{4 cm}
\null\hfill \textbf{Desarrollado por:}
\\
\null\hfill Víctor Páez Anguita
\clearpage
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%Index%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents
\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%Index%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Requisitos}

\begin{itemize}
  \item El proyecto deberá tener todo el stack de todos los sistemas vistos en clase perfectamente instalado, configurado y funcionando como un 
  Sistema completo de Big Data, desde la ingesta de datos, ETL, BI y su visualización.

  \item El alumnado elegirá el origen, los tipos y la temática de los datos que se van a procesar en el Sistema Big Data.
  
  \item Deben establecer, desarrollar y justificar el tipo de conocimiento que van a obtener de los datos origen después de su ingesta y 
  procesamiento (ETL) en el sistema.

  \item El procesamiento de los datos lo realizarán a través de SPARK, utilizando alguna de sus 3 APIs disponibles. Esto no quita que puedan 
  realizar algún tipo de procesamiento de datos anteriormente, como por ejemplo en Kafka.

  \item El sistema debe poder soportar la ingesta de datos tanto en batch como en streaming.
  
  \item Los datos de origen podrán ser sintéticos, reales o una combinación de ambos.
  
  \item Puedes usar las Api/s que creas necesaria/s. Incluso la creación de tus propios datos sintéticos en batch y streaming 
  (Estos deben cumplir con los requisitos del puntos 1 al 3)

  \item Todo el ETL realizado deberá estar correctamente desarrollado y justificado.
  
  \item Se deberá añadir al stack algún sistema, servicio, ... de investigación propia 
  (al menos 1, aunque puede añadir todos los que quieras). Se propone una lista de ellos, 
  que podrán ser ampliados a propuesta del alumnado:

  \begin{itemize}
    \item AWS GLUE
    \item AWS S3
    \item Nifi
    \item Flink
    \item Tableau
    \item PowerBI
    \item Elasticsearch
    \item Kibana
    \item RabbitMQ
    \item Otros (deben ser consensuados y aprobados)
  \end{itemize}

  \item La calificación del proyecto se hará de forma global, dependiendo de los niveles de aprendizaje que se demuestres superados acorde 
  al nivel de conocimiento que exige el módulo del CE.
\end{itemize}

\subsection{Proyectos. Requisitos mínimos}
\begin{itemize}
  \item El sistema completo será, como mínimo (más la investigación propia):
  \begin{itemize}
    \item Apache Hadoop Common
    \item HDFS
    \item MapReduce
    \item Yarn
    \item SPARK
    \item Grafana
  \end{itemize}
  \item Debe haber como mínimo 3 nodos en los clusters (en cada uno):
  \begin{itemize}
    \item Hadoop (HDFS/Yarn)
    \item Spark
    \item Kafka
  \end{itemize}
  \item Añade todos los nodos que necesites para desplegar todo el stack Big Data del proyecto.
  \item Deben soportar acceso concurrente desde varios nodos Edge.
\end{itemize}

\subsection{Consideraciones}

\begin{itemize}
  \item A mayor y mejor ETL y mayor y mejor Business Intelligence, mejor calificación.
  \item Si un proyecto no tiene suficiente procesamiento de datos y obtención de conocimiento, 
  mayor será la exigencia de la investigación propia o viceversa.
\end{itemize}

\clearpage

\section{Introducción}

AsteroidTracking consiste en el desarrollo de un sistema completo de Big Data cuyo objetivo es la detección 
y análisis en tiempo real de objetos cercanos a la Tierra (NEOs, por sus siglas en inglés), como asteroides,
cometas, satélites y otros tipos de objetos potencialmente peligrosos. La idea principal es obtener estos datos
a partir de un conjunto de datos base real proporcionado por la API de la NASA  \cite[(Sentry System)]{Sentry-System}.
El inconveniente es que este conjunto de datos no es lo suficientemente grande ni contiene datos en tiempo real,
por lo que he obtado por generar datos sintéticos.
\\
\\
El objetivo final es crear un bussiness Intelligence que permita la visualización y análisis de estos datos,
descubriendo patrones y tendencias que puedan ayudar a identificar que objetos y que características son
potencialmente peligrosos, así como la posibilidad de generar alertas en función de parámetros críticos como
la proximidad, la masa o la velocidad del asteroide.
\\
\\
El sistema implementa todo el stack tecnológico necesario. Teniendo una arquitectura basada en 
un clúster de Apache hadoop desplegado en un entorno distribuido con HDFS, que permite realizar
la ingesta de datos con un cluster de kafka que se encargará de recibir
los datos en tiempo real y almacenarlos en un topic. para su posterior procesamiento utilizando
las APIs de Spark Streaming y Spark SQL.
\\
\\
Los datos origen han sido diseñados para incluir valores realistas como si recopilarlos de la imagen
de un telescopio se tratase (como diametro, brillo del objeto y ruido de la imagen(simulando la interferencia)), 
junto con datos erróneos o incompletos, con el fin de justificar y aplicar transformaciones durante la fase de ETL.
La información que se prentende extraer de estos datos son metricas que nos ayudaran a extraer conocimiento como
(superficie, velocidad, distancia, masa, etc.).
\\
\\
Mediante la integración de Prometheus y Grafana, se realizarán las correspondientes visualizaciones 
a través de los dashboards para facilitar la toma de decisiones y el análisis exploratorio de 
los resultados.

\clearpage

\section{Arquitectura del sistema}

Para el desarrollo de este proyecto se ha utilizado una arquitectura distribuida basada en un clúster de Apache Hadoop,
que permite el procesamiento y almacenamiento de grandes volúmenes de datos. El clúster está compuesto por 4 maquinas virtuales,
las cuales 1 de ellas actúa como nodo maestro y las otras 3 como nodos esclavos.
El nodo maestro se encarga de gestionar el clúster, coordinando las tareas de procesamiento y almacenamiento,
mientras que los nodos esclavos se encargan de ejecutar las tareas de procesamiento y almacenamiento de datos.

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/maquinas.PNG}
    \caption{Maquinas virtuales del clúster}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/cluster.png}
    \caption{Controller y brokers}
    \label{fig:my_label}
\end{figure}

\clearpage

\section{Genereación de datos sintéticos}

Como he mencionado anteriormente, el conjunto de datos se genera de forma sintética para simular la ingesta de datos en tiempo real.
Para ello, se ha utilizado la librería Faker \cite[Faker]{joke2k-faker} y \cite[numpy]{numpy} que permite generar datos sintéticos 
de forma aleatoria y realista. El script que se encargará de esto es \texttt{neo\_generate\_synthetic\_data.py}, (el cual se
encuentra dentro de la carpeta \texttt{src/scripts}) del repositorio. Dentro del script tenemos las respetivas funciones
que se encargaran de generar los datos. Simulando la recolecta de información de un telescopio (diametro, brillo del objeto y 
ruido de la imagen), además de la generación de coordenadas celestiales sobre estos objetos (horas y grados).
\\
Finalmente tenemos la generación de un archivo pipe o FIFO que se encargará de recoger estos datos en formato JSON y enviarlos 
al productor de Kafka para simular la ingesta de datos en tiempo real de una API. El script \texttt{neo\_data\_producer.py} 
actuará como productor, recibiendo los datos del archivo pipe y enviándolos al topic de Kafka correspondiente.

\section{procesamiento de datos (ETL)}

Para el procesamiento de datos se ha utilizado Apache Spark, que permite el procesamiento de grandes volúmenes de datos de 
forma distribuida. Teniendo 3 archivos que actuarán como workers, los cuales se encargarán de procesar los datos
recibidos del topic de Kafka \texttt{neo\_raw\_data}. Para ello tenemos el script \texttt{spark\_asteroidTrackingProcessing.py}, que se
encargará de:

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/worker1.PNG}
    \caption{Ejemplo de worker}
    \label{fig:my_label}
\end{figure}

\subsection{Consumidor}
Utiliza Spark Structured Streaming para:

\begin{itemize}
  \item Conectarse al broker Kafka (192.168.11.10:9094).
  \item Leer mensajes en tiempo real del tópico \texttt{neo\_raw\_data}.
  \item Interpretar cada mensaje como un JSON que contiene información observacional 
        (timestamp, coordenadas, diámetro, brillo, ruido, etc.).
\end{itemize}

\subsection{Transformación de datos}
Una vez leídos los datos en bruto, se aplican transformaciones para calcular métricas físicas y orbitales de cada asteroide:
\\
\begin{itemize}
  \item Se le asigna un identificador único a cada asteroide (simulando a como se identifican en la realidad, pero puesto que son sinteticos
  y necesitamos variedad se hará de forma aleatoria).
  \begin{itemize}
    \item YYYY es el año de la observación
    \item L1, L2 son letras aleatorias (excepto "I" y "Z" en algunas posiciones)(simulando el sistema de clasificación de asteroides por quincenas).
    \item NN es un número aleatorio entre 01 y 99 (simulando el número de descubrimiento del objeto).
  \end{itemize}
\end{itemize}
Este identificador sigue una simplificación de las reglas reales del Minor Planet Center.
\\
Cada objeto generado tiene una aleatoriedad de replica que introduce variaciones en los datos para simular el seguimiento del objeto.
Siguiendo a las metricas tenemos:
\\
\begin{itemize}
  \item Conversión de RA/DEC a coordenadas cartesianas tridimensionales (x, y, z) para averiguar la distancia del asteroide a la Tierra.
\end{itemize}
Asumiendo una distancia fija d=1,000,000 km al objeto, se transforma la posición desde coordenadas esféricas RA/DEC a cartesianas:
\begin{align*}
  \text{RA}_{\text{rad}} &= \text{RA}_{\text{hours}} \times 15 \times \frac{\pi}{180} \\
  \text{DEC}_{\text{rad}} &= \text{DEC}_{\text{deg}} \times \frac{\pi}{180} \\
  x &= d \cdot \cos(\text{DEC}_{\text{rad}}) \cdot \cos(\text{RA}_{\text{rad}}) \\
  y &= d \cdot \cos(\text{DEC}_{\text{rad}}) \cdot \sin(\text{RA}_{\text{rad}}) \\
  z &= d \cdot \sin(\text{DEC}_{\text{rad}})
\end{align*}

\begin{itemize}
  \item Distancia mínima al origen (en km y UA)
\end{itemize}

\begin{align*}
  \text{distancia}_{\text{km}} &= \sqrt{x^2 + y^2 + z^2} \\
  \text{distancia}_{\text{AU}} &= \frac{\text{distancia}_{\text{km}}}{149{,}597{,}870.7}
\end{align*}

\begin{itemize}
  \item Cálculo de propiedades físicas (A partir del diámetro se derivan múltiples propiedades físicas)
  \begin{itemize}
    \item Radio:
      \begin{align*}
        r &= \frac{d}{2}
      \end{align*}
    \item Volumen del asteroide (asumido esférico):
      \begin{align*}
        V &= \frac{4}{3} \pi r^3
      \end{align*}
    \item Área superficial:
      \begin{align*}
        A &= 4 \pi r^2
      \end{align*}
    \item Densidad: valor fijo típico para roca: p=2600 kg/m3
    \item Masa:
      \begin{align*}
        m &= V \cdot p
      \end{align*}
    \item Velocidad de escape:
      \begin{align*}
        v_{\text{escape}} &= \sqrt{\frac{2 G m}{r}}
      \end{align*}
  \end{itemize}
\end{itemize}

Donde:
\begin{itemize}
  \item d: diámetro en metros
  \item r: radio
  \item p=2600 kg/m3
  \item $\text{G}=6.67430\times 10^{-11}\,\text{m}^3\text{kg}^{-1}\text{s}^{-2}$
\end{itemize}

\begin{itemize}
  \item Parámetros orbitales básicos
  \begin{itemize}
    \item Eje semi-mayor (suponiendo órbita elíptica):
      \begin{align*}
        a &= \text{distancia}_{\text{AU}} \cdot 149{,}597{,}870{,}700 \text{ m}
      \end{align*}
    \item Excentricidad: valor fijo: e=0.3
    \item Período orbital (en segundos y días):
      \begin{align*}
        T &= 2 \pi \sqrt{\frac{a^3}{G m}} \\
        T_{\text{días}} &= \frac{T}{86400}
      \end{align*}
    \item Inclinación orbital: valor fijo: i=10 grados
  \end{itemize}
\end{itemize}

\begin{itemize}
  \item Cálculo de elementos orbitales avanzados
  \begin{itemize}
    \item Periapsis y apoapsis:
      \begin{align*}
        q &= a \cdot (1 - e) \\
        Q &= a \cdot (1 + e)
      \end{align*}
    \item ¿Cruza la órbita terrestre? (Se compara si el perihelio es menor a 1.017 UA y el afelio mayor a 0.983 UA)
      \begin{align*}
        \text{Cruza órbita terrestre} \iff
        \left(q < 1.017 \, \text{AU}\right) \land \left(Q > 0.983 \, \text{AU}\right)
      \end{align*}
    \item Factor de sincronía (para calcular la probabilidad de impacto):
      \begin{align*}
        \text{Factor de sincronía} = \frac{1}{\max\left(1, \left|T_{\text{días}} - 365.25\right|\right)}
      \end{align*}
  \end{itemize}
\end{itemize}

\begin{itemize}
  \item Probabilidad de impacto
\end{itemize}

Si el objeto cruza la órbita terrestre, la probabilidad de impacto se estima mediante una fórmula determinista que considera tamaño, 
distancia y sincronía temporal:

\begin{align*}
  P_{\text{impacto}} =
  \left( \frac{\left(\frac{d}{1000}\right)^2}{\text{distancia}_{\text{AU}}^2 + 0.1} \right)
  \cdot \text{Factor de sincronía} \cdot 0.01
\end{align*}

\begin{itemize}
  \item Clasificación de nivel de amenaza (Según el valor de P impacto, se clasifica el riesgo)
  \begin{itemize}
    \item ALTO si P>0.05
    \item MEDIO si 0.01<P<=0.05
    \item BAJO si P<=0.01
  \end{itemize}
\end{itemize}

Como podemos ver son calculos para metricas fisicas y orbitales que nos permitiran obtener conocimiento sobre cada objeto y el comportamiento
de estos. Dando la posibilidad de realizar analisis y visualizaciones sobre estos datos. Esta seria la estructura del JSON que se generará yml
se almacenará en HDFS:

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/json.PNG}
    \caption{Estructura JSON de los datos enriquecidos}
    \label{fig:my_label}
\end{figure}

\subsection{Almacenamiento en HDFS}

Los datos enriquecidos se escriben directamente en HDFS, usando el formato JSON (en formato JSON para dar más versatilidad a
los datos). La escritura está configurada para:

\begin{itemize}
  \item Guardar en la ruta: \texttt{hdfs://cluster-bda:9000/bda/kafka/AsteroidTracking}
  \item Organizar los datos en carpetas por:
  \begin{itemize}
    \item Tópico (topic=asteroid-events)
    \item Partición lógica Spark (partition=X)
    \item Fecha (date=YYYY-MM-DD)
  \end{itemize}
\end{itemize}

\begin{verbatim}
  query = (out_df
    .writeStream
    .format("json")
    .partitionBy("topic", "partition", "date")
    .option("path", "hdfs://cluster-bda:9000/bda/kafka/AsteroidTracking")
    .option("checkpointLocation", "hdfs://cluster-bda:9000/bda/kafka
    /AsteroidTracking/checkpoints/asteroid-stream")
    .outputMode("append")
    .start())
\end{verbatim}

El uso de checkpointLocation garantiza tolerancia a fallos y recuperación del estado del stream.

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/hdfs.PNG}
    \caption{Controller y brokers}
    \label{fig:my_label}
\end{figure}

\section{Visualización}

Para la visualización de los datos como he mencionado anteriormente, se implementó una arquitectura de monitorización y visualización 
utilizando Prometheus y Grafana, con el objetivo de supervisar tanto las métricas técnicas del sistema como los indicadores 
científicos derivados del procesamiento de los asteroides.

\subsection{Prometheus + JMX Exporter}

Prometheus fue configurado como sistema de monitorización principal. A través del JMX Exporter, se habilitó la recolección de métricas 
JVM en los servicios Spark y Kafka, permitiendo supervisar su rendimiento en tiempo real: uso de CPU, memoria, latencia de 
procesamiento y throughput.

\subsection{Exportador personalizado}

Además de las métricas del sistema, hay un exportador personalizado \texttt{asteroid\_exporter.py} con el objetivo de 
exponer métricas científicas enriquecidas sobre los asteroides procesados por Spark.
Este exportador se encarga de conectarse a HDFS a través de WebHDFS para acceder directamente a los archivos JSON enriquecidos generados 
por Spark Streaming. Luego recorre todas las particiones y fechas disponibles para procesar los datos sin necesidad de descargarlos previamente.
Finalmente expone las métricas en formato Prometheus en el puerto :9091, tanto agregadas como individuales que son recogidas por 
Prometheus por un job definido en \texttt{prometheus\_asteroidTracking\_mon\_kafka.yml}

\subsection{Dashboards de Grafana}

Para visualizar las métricas generadas por el exportador, se diseñó un dashboard en Grafana \texttt{asteroid\_dashboard.json} 
que ofrece una visión clara, interactiva y dinámica del estado actual de los asteroides detectados.
El dashboard contiene los siguientes paneles:
\begin{itemize}
  \item Número de asteroides procesados: gráfico de líneas que muestra la evolución del número de asteroides procesados en tiempo real.
  \item Distribución de amenaza: gráfico tipo donut que muestra el porcentaje de objetos clasificados como 
  ALTO, MEDIO o BAJO. Incluye enlaces interactivos que permiten filtrar el resto de paneles por nivel de amenaza.
  \item Top 50 asteroides por probabilidad de impacto: tabla ordenada por la métrica
  \\ 
  \texttt{asteroid\_impact\_probability}, 
  útil para identificar rápidamente los objetos más peligrosos.
  \item Tabla unilineal del asteroide seleccionado: muestra información detallada.
  \item Comparativa de masa y densidad: gráfico de barras que muestra la masa o densidad a lo largo del tiempo.
  \item Evolución de la distancia mínima (AU): gráfico de líneas que muestra la distancia mínima estimada para cada asteroide con 
  posibilidad de impacto, permitiendo observar su evolución en tiempo real.
\end{itemize}

Además, el dashboard incluye variables globales para filtrar la visualización por:
\begin{itemize}
  \item Nivel de amenaza (threatVar): todos, ALTO, MEDIO, BAJO.
  \item Periodo orbital máximo (periodMax): filtra los asteroides cuyo período orbital está por debajo de un umbral definido en días.
  \item Selección de asteroide (asteroidVar): permite seleccionar un asteroide específico para ver su información detallada en la tabla unilineal.
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/dashboard.PNG}
    \caption{Dashboard}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=.7\textwidth]{assets/proyecto/dashboard-2.PNG}
    \caption{Dashboard}
    \label{fig:my_label}
\end{figure}

\clearpage

\section{Business Intelligence}

Gracias al conjunto de datos enriquecidos y las métricas generadas, se pueden realizar análisis exploratorios para descubrir patrones y 
tendencias en los objetos cercanos a la Tierra, tanto para aplicaciones científicas como operativas.

\subsection{Detección y evaluación de riesgo en tiempo real}
\begin{itemize}
  \item Se identifican asteroides cercanos.
  \item Se calcula su probabilidad de impacto usando una fórmula determinista basada en distancia mínima, diámetro, 
  sincronía orbital y cruce con la órbita terrestre.
  \item Se clasifican en niveles de amenaza (ALTO, MEDIO, BAJO) para priorizar la atención.
  \item Distribución histórica de amenazas por nivel.
  \item Visualización de la evolución del objeto a lo largo del tiempo.
  \item Visualización de metricas físicas y orbitales de los asteroides para determinar su comportamiento y características.
  \item Cuáles podrían requerir atención técnica o monitoreo adicional.
  \item Qué asteroides tienen mayor probabilidad de retorno cercano en el futuro.
\end{itemize}
\subsection{Simulación de escenarios y entrenamiento de modelos}
\begin{itemize}
  \item Entrenar modelos de predicción de impacto.
  \item Validar algoritmos de clasificación automática.
  \item Generar datasets para entrenar modelos de machine learning.
  \item Simular escenarios de impacto y evaluar consecuencias.
\end{itemize}
\subsection{Investigación científica}
\begin{itemize}
  \item Estudiar la composición y estructura de los asteroides.
  \item Analizar la evolución de sus órbitas a lo largo del tiempo.
  \item Investigar la formación y dinámica del sistema solar.
  \item Comparar propiedades físicas con otros cuerpos celestes.
  \item Identificar patrones en la distribución espacial de los NEOs.
\end{itemize}

\clearpage

\section{Conclusión}

AsteroidTracking es un sistema completo de Big Data que permite la detección y análisis en tiempo real de objetos cercanos a la Tierra,
utilizando un conjunto de sinteticos basados en observaciones parecidas a las reales simulando una ingesta de datos en tiempo real.
El sistema implementa todo el stack tecnológico necesario, desde la ingesta de datos con Kafka, el procesamiento de datos con Spark,
hasta la visualización de los resultados con Grafana.
\\
En el repositorio de Github se puede encontrar el código fuente utilizado para cada script del proyecto y su configuración del cluster. Así como
un video demostrativo del funcionamiento del sistema.

\clearpage

\section{Bibliografia}

\cite{neows-api}
\cite{Sentry-System}
\cite{joke2k-faker}
\cite{numpy}
\cite{spark}
\cite{kafka}
\cite{prometheus}
\cite{grafana}
\cite{Standard-asteroids-physical-characteristics}
\cite{Movimiento-Orbital}
\cite{Impact-probability}


\printbibliography

\end{document}